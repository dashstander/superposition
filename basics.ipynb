{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "048d153a-8a69-488c-877b-45a12640327e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "from dataclasses import dataclass, replace\n",
    "import numpy as np\n",
    "import einops\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import time\n",
    "import polars as pl\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "\n",
    "import torchopt\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dad78654-21db-44df-8432-5091e852adbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1bb3970f-3948-4bbe-a099-d98f434a3b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import relu\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "  n_features: int\n",
    "  n_hidden: int\n",
    "\n",
    "  # We optimize n_instances models in a single training loop\n",
    "  # to let us sweep over sparsity or importance curves \n",
    "  # efficiently.\n",
    "\n",
    "  # We could potentially use torch.vmap instead.\n",
    "  n_instances: int\n",
    "\n",
    " \n",
    "class Model(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.W0 = nn.Parameter(torch.empty((config.n_hidden, config.n_features)))\n",
    "        self.b_init = nn.Parameter(torch.zeros((config.n_hidden,), device=device))\n",
    "        nn.init.xavier_normal_(self.W0)\n",
    "        self.W1 = nn.Parameter(torch.empty((config.n_features, config.n_hidden)))\n",
    "        nn.init.xavier_normal_(self.W1)\n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, features):\n",
    "    # features: [..., instance, n_features]\n",
    "    # W: [instance, n_features, n_hidden]\n",
    "        hidden = torch.einsum('bi,hi->bh', features, self.W0) + self.b_init\n",
    "        out = torch.einsum('bh,ih->bi', relu(hidden), self.W1)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class SparseUniformData:\n",
    "\n",
    "    def __init__(self, n_instances, n_features, importance=None, feature_probability=None, device='cuda:0'):\n",
    "        self.n_instances = n_instances\n",
    "        self.n_features = n_features\n",
    "        if feature_probability is None:\n",
    "            feature_probability = torch.ones(())\n",
    "        self.feature_probability = feature_probability.to(device)\n",
    "        if importance is None:\n",
    "            importance = torch.ones(())\n",
    "        self.importance = importance.to(device)\n",
    "        self.device = device\n",
    "    \n",
    "    def generate(self, n_batch):\n",
    "        feat = torch.zeros((self.n_instances, n_batch, self.n_features), device=self.device).squeeze()\n",
    "        feat.uniform_(-1, 1)\n",
    "        batch = torch.where(\n",
    "          torch.rand((self.n_instances, n_batch, self.n_features), device=self.device).squeeze() <= self.feature_probability,\n",
    "          feat,\n",
    "          torch.zeros((), device=self.device),\n",
    "        )\n",
    "        return batch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d7f84594-7fb7-4188-9383-ef22dff04ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 8.0508e-01, -2.9350e-01,  9.1229e-03,  1.5904e-01],\n",
       "        [ 1.8247e-01, -9.2906e-02, -5.6088e-02, -1.3026e-01],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 2.0520e-01, -8.3162e-02, -1.6093e-02, -1.2135e-02],\n",
       "        [ 2.2955e-02, -1.1688e-02, -7.0559e-03, -1.6387e-02],\n",
       "        [ 3.1415e-02, -1.9162e-02, -1.6638e-02, -4.2391e-02],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 1.6670e-01, -5.1539e-02,  2.2242e-02,  9.1134e-02],\n",
       "        [ 1.7544e-01, -7.1100e-02, -1.3758e-02, -1.0375e-02],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 2.0987e-01, -6.4885e-02,  2.8001e-02,  1.1473e-01],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 2.0813e-02, -1.2695e-02, -1.1022e-02, -2.8084e-02],\n",
       "        [ 7.6729e-02, -2.3722e-02,  1.0238e-02,  4.1947e-02],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 3.5321e-01, -1.3134e-01, -1.6725e-03,  5.3544e-02],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 9.6587e-01, -4.0948e-01, -1.1550e-01, -1.7081e-01],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 1.2775e-01, -3.9498e-02,  1.7046e-02,  6.9843e-02],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 1.0344e+00, -3.8463e-01, -4.8980e-03,  1.5681e-01],\n",
       "        [ 9.8789e-01, -3.5416e-01,  2.4379e-02,  2.3285e-01],\n",
       "        [ 7.1214e-01, -2.6481e-01, -3.3721e-03,  1.0796e-01],\n",
       "        [ 1.2805e-01, -3.9590e-02,  1.7085e-02,  7.0005e-02],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 2.0945e-01, -1.0664e-01, -6.4381e-02, -1.4952e-01],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 6.2691e-02, -3.8239e-02, -3.3201e-02, -8.4593e-02],\n",
       "        [ 1.0107e+00, -3.7583e-01, -4.7858e-03,  1.5322e-01],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 2.4983e-01, -8.7942e-02,  9.7435e-03,  6.9119e-02],\n",
       "        [ 1.0683e-01, -4.3295e-02, -8.3778e-03, -6.3175e-03],\n",
       "        [ 2.5133e-02, -7.7704e-03,  3.3534e-03,  1.3740e-02],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 1.9401e-01, -5.9981e-02,  2.5885e-02,  1.0606e-01],\n",
       "        [ 1.2203e-01, -3.7729e-02,  1.6282e-02,  6.6715e-02],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 1.3727e-01, -4.2440e-02,  1.8315e-02,  7.5045e-02],\n",
       "        [ 2.1381e-01, -8.6654e-02, -1.6768e-02, -1.2644e-02],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 1.0573e+00, -3.9087e-01, -3.3643e-06,  1.7458e-01],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 1.3299e-01, -4.1115e-02,  1.7744e-02,  7.2703e-02],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 1.1884e+00, -4.4192e-01, -5.6274e-03,  1.8016e-01],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 1.3503e+00, -5.0106e-01, -4.0690e-03,  2.1135e-01],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 3.3951e-01, -1.2625e-01, -1.6077e-03,  5.1468e-02],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 5.4136e-02, -3.3021e-02, -2.8670e-02, -7.3049e-02],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 1.2366e+00, -4.5984e-01, -5.8557e-03,  1.8747e-01],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 2.1401e-01, -8.6732e-02, -1.6783e-02, -1.2656e-02],\n",
       "        [ 3.0677e-01, -1.5619e-01, -9.4295e-02, -2.1900e-01],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 1.3889e+00, -5.0735e-01,  1.3457e-02,  2.6783e-01],\n",
       "        [ 2.2090e-02, -1.3474e-02, -1.1699e-02, -2.9808e-02]], device='cuda:0',\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.func import functional_call, stack_module_state\n",
    "import copy\n",
    "\n",
    "config = Config(\n",
    "    n_features = 4,\n",
    "    n_hidden = 2,\n",
    "    n_instances = 1,\n",
    ")\n",
    "\n",
    "device = 'cuda:0'\n",
    "\n",
    "model = Model(\n",
    "    config=config,\n",
    "    # Exponential feature importance curve from 1 to 1/100\n",
    "    #importance = (0.9**torch.arange(config.n_features))[None, :],\n",
    "    # Sweep feature frequency across the instances from 1 (fully dense) to 1/20\n",
    "    #feature_probability = (20 ** -torch.linspace(0, 1, config.n_instances))[:, None]\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "#models = [Model(config).to(device) for _ in range(config.n_instances)]\n",
    "\n",
    "stream = SparseUniformData(\n",
    "    config.n_instances,\n",
    "    config.n_features,\n",
    "    # Exponential feature importance curve from 1 to 1/100\n",
    "    #importance = (0.9**torch.arange(config.n_features))[None, :],\n",
    "    # Sweep feature frequency across the instances from 1 (fully dense) to 1/20\n",
    "    feature_probability = torch.tensor(0.2)   #(20 ** -torch.linspace(0, 1, config.n_instances))[:, None, None]\n",
    ")\n",
    "\n",
    "#base_model = copy.deepcopy(models[0])\n",
    "#base_model = base_model.to('meta')\n",
    "\n",
    "#def fmodel(params, x):\n",
    "#    return functional_call(base_model, (params,), (x,))\n",
    "model(stream.generate(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7c98fd13-7c9a-4d2c-914c-10116aa7d8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import trange\n",
    "\n",
    "\n",
    "def linear_lr(step, steps):\n",
    "    return (1 - (step / steps))\n",
    "\n",
    "def constant_lr(*_):\n",
    "    return 1.0\n",
    "\n",
    "def cosine_decay_lr(step, steps):\n",
    "    return np.cos(0.5 * np.pi * step / (steps - 1))\n",
    "\n",
    "def optimize(model, stream, n_batch=1024, steps=10_000, print_freq=100, lr=1e-3, hooks=[]):\n",
    "    cfg = model.config\n",
    "\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "    start = time.time()\n",
    "    with trange(steps) as run:\n",
    "        for step in run:\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            batch = stream.generate(n_batch)\n",
    "            out = model(batch)\n",
    "            loss = ((batch.abs() - out) ** 2).mean(dim=1).sum()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        \n",
    "            if hooks:\n",
    "                hook_data = dict(\n",
    "                    model=model,\n",
    "                    step=step, \n",
    "                    opt=opt,\n",
    "                    error=error,\n",
    "                    loss=loss,\n",
    "                    lr=step_lr\n",
    "                )\n",
    "            for h in hooks:\n",
    "              h(hook_data)\n",
    "            if step % print_freq == 0 or (step + 1 == steps):\n",
    "                run.set_postfix(\n",
    "                    loss=loss.item() / cfg.n_instances,\n",
    "                    lr=lr,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "baab57a9-b6c7-4fa9-a8a5-f42a6edd9321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f30036b58934e09a269a7c439cd8206",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = Config(\n",
    "    n_features = 10,\n",
    "    n_hidden = 6,\n",
    "    n_instances = 1,\n",
    ")\n",
    "\n",
    "model = Model(\n",
    "    config=config,\n",
    "    # Exponential feature importance curve from 1 to 1/100\n",
    "    #importance = (0.9**torch.arange(config.n_features))[None, :],\n",
    "    # Sweep feature frequency across the instances from 1 (fully dense) to 1/20\n",
    "    #feature_probability = torch.tensor(0.1) #(20 ** -torch.linspace(0, 1, config.n_instances))[:, None]\n",
    ")\n",
    "\n",
    "stream = SparseUniformData(\n",
    "    config.n_instances,\n",
    "    config.n_features,\n",
    "    # Exponential feature importance curve from 1 to 1/100\n",
    "    importance = (0.9**torch.arange(config.n_features))[None, :],\n",
    "    # Sweep feature frequency across the instances from 1 (fully dense) to 1/20\n",
    "    feature_probability = torch.tensor(0.05)   #(20 ** -torch.linspace(0, 1, config.n_instances))[:, None, None]\n",
    ")\n",
    "\n",
    "model.to('cuda:0')\n",
    "\n",
    "#batch = stream.generate(100)\n",
    "#out = model(batch)\n",
    "\n",
    "\n",
    "optimize(model, stream, n_batch=4096, steps=20_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5171f12c-1b94-439a-a670-91de0f87d6ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(13.3053, device='cuda:0', grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8138c7a3-84fd-4161-811d-f952fb18d1dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-8.4099e-05,  1.6878e-06, -1.5034e+00, -4.3521e-05,  1.9523e-04],\n",
       "        [-1.4828e-04,  1.0427e+00, -1.2173e-04, -6.3594e-05,  2.5983e-04]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.W0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bb6d6dfe-d491-4f1a-8c27-7ee5d95ab760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1280x960 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import colors  as mcolors\n",
    "from matplotlib import collections  as mc\n",
    "\n",
    "def plot_intro_diagram(model, stream):\n",
    "\n",
    "    cfg = model.config\n",
    "    W0_A = model.linear0.weight\n",
    "    W1_A = model.linear1.weight\n",
    "    N = len(W0_A[:,0])\n",
    "    sel = range(config.n_instances) # can be used to highlight specific sparsity levels\n",
    "    #plt.rcParams[\"axes.prop_cycle\"] = plt.cycler(\"color\", plt.cm.viridis(stream.importance.cpu().numpy()))\n",
    "    plt.rcParams['figure.dpi'] = 200\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    W = W0_A.cpu().detach().numpy()\n",
    "    #colors = [mcolors.to_rgba(c)\n",
    "    #    for c in plt.rcParams['axes.prop_cycle'].by_key()['color']]\n",
    "    #ax.scatter(W[:,0], W[:,1], c=colors[0:len(W[:,0])])\n",
    "    ax.scatter(W[:,0], W[:,1])\n",
    "    ax.set_aspect('equal')\n",
    "    #ax.add_collection(mc.LineCollection(np.stack((np.zeros_like(W),W), axis=1), colors=colors))\n",
    "    ax.add_collection(mc.LineCollection(np.stack((np.zeros_like(W),W), axis=1)))\n",
    "    \n",
    "    z = 1.5\n",
    "    ax.set_facecolor('#FCFBF8')\n",
    "    ax.set_xlim((-z,z))\n",
    "    ax.set_ylim((-z,z))\n",
    "    ax.tick_params(left = True, right = False , labelleft = False ,\n",
    "              labelbottom = False, bottom = True)\n",
    "    for spine in ['top', 'right']:\n",
    "        ax.spines[spine].set_visible(False)\n",
    "    for spine in ['bottom','left']:\n",
    "        ax.spines[spine].set_position('center')\n",
    "    plt.show()\n",
    "\n",
    "plot_intro_diagram(model, stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dd0a4c73-cc04-4575-abce-2dc7b5d1c31e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.3558461e-01, -7.0413970e-04],\n",
       "       [ 1.0101963e-04,  9.9034435e-01],\n",
       "       [ 3.1240564e-04, -7.4370539e-01],\n",
       "       [-1.1632881e+00,  8.4953579e-05],\n",
       "       [ 1.2330844e+00, -1.3950655e-04]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = W0_A.cpu().detach().numpy()\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c5f7b4e9-e092-44e0-9c4a-7d83ec0820ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1280x960 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cfg = model.config\n",
    "W0_A = model.linear0.weight\n",
    "W1_A = model.linear1.weight\n",
    "N = len(W0_A[:,0])\n",
    "sel = range(config.n_instances) # can be used to highlight specific sparsity levels\n",
    "#plt.rcParams[\"axes.prop_cycle\"] = plt.cycler(\"color\", plt.cm.viridis(stream.importance.cpu().numpy()))\n",
    "plt.rcParams['figure.dpi'] = 200\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "W = W0_A.cpu().detach().numpy()\n",
    "#colors = [mcolors.to_rgba(c)\n",
    "#    for c in plt.rcParams['axes.prop_cycle'].by_key()['color']]\n",
    "#ax.scatter(W[:,0], W[:,1], c=colors[0:len(W[:,0])])\n",
    "ax.scatter(W[:,0], W[:,1])\n",
    "ax.set_aspect('equal')\n",
    "#ax.add_collection(mc.LineCollection(np.stack((np.zeros_like(W),W), axis=1), colors=colors))\n",
    "ax.add_collection(mc.LineCollection(np.stack((np.zeros_like(W),W), axis=1)))\n",
    "\n",
    "z = 1.5\n",
    "ax.set_facecolor('#FCFBF8')\n",
    "ax.set_xlim((-z,z))\n",
    "ax.set_ylim((-z,z))\n",
    "ax.tick_params(left = True, right = False , labelleft = False ,\n",
    "          labelbottom = False, bottom = True)\n",
    "for spine in ['top', 'right']:\n",
    "    ax.spines[spine].set_visible(False)\n",
    "for spine in ['bottom','left']:\n",
    "    ax.spines[spine].set_position('center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b198d43d-1cdc-4f33-b75b-006d19738d43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.1052375e+00, -7.9472713e-02],\n",
       "       [ 1.9320844e-01, -1.0739383e+00],\n",
       "       [-9.9909025e-01, -4.6647742e-01],\n",
       "       [ 2.8025672e-02, -2.2381398e-01],\n",
       "       [-7.2942275e-01,  7.8876936e-01],\n",
       "       [-9.5745077e-04,  1.6257060e-03],\n",
       "       [-1.3350666e-04, -4.6174368e-04],\n",
       "       [ 3.9898586e-01,  9.2390126e-01]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8af37266-09c5-4e0c-95e2-ba9241c549c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.func import functional_call\n",
    "import copy\n",
    "\n",
    "# Construct a \"stateless\" version of one of the models. It is \"stateless\" in\n",
    "# the sense that the parameters are meta Tensors and do not have storage.\n",
    "base_model = copy.deepcopy(models[0])\n",
    "base_model = base_model.to('meta')\n",
    "\n",
    "def fmodel(params, x):\n",
    "    return functional_call(base_model, (params,), (x,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e6a433c4-a77b-41b1-a5fd-ee7880bb4d3b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (100) must match the size of tensor b (10) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m batch \u001b[38;5;241m=\u001b[39m generator\u001b[38;5;241m.\u001b[39mgenerate_batch(\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mfmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[22], line 10\u001b[0m, in \u001b[0;36mfmodel\u001b[0;34m(params, x)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfmodel\u001b[39m(params, x):\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunctional_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/superposition/.venv/lib/python3.10/site-packages/torch/_functorch/functional_call.py:143\u001b[0m, in \u001b[0;36mfunctional_call\u001b[0;34m(module, parameter_and_buffer_dicts, args, kwargs, tie_weights, strict)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    139\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected parameter_and_buffer_dicts to be a dict, or a list/tuple of dicts, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    140\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(parameter_and_buffer_dicts)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    141\u001b[0m     )\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstateless\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_functional_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparameters_and_buffers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtie_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtie_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/superposition/.venv/lib/python3.10/site-packages/torch/nn/utils/stateless.py:264\u001b[0m, in \u001b[0;36m_functional_call\u001b[0;34m(module, parameters_and_buffers, args, kwargs, tie_weights, strict)\u001b[0m\n\u001b[1;32m    260\u001b[0m     args \u001b[38;5;241m=\u001b[39m (args,)\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _reparametrize_module(\n\u001b[1;32m    262\u001b[0m     module, parameters_and_buffers, tie_weights\u001b[38;5;241m=\u001b[39mtie_weights, strict\u001b[38;5;241m=\u001b[39mstrict\n\u001b[1;32m    263\u001b[0m ):\n\u001b[0;32m--> 264\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/superposition/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/superposition/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[18], line 62\u001b[0m, in \u001b[0;36mModel.forward\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, features):\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# features: [..., n_features]\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# W: [n_features, n_hidden]\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     hidden \u001b[38;5;241m=\u001b[39m features \u001b[38;5;241m@\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW\n\u001b[0;32m---> 62\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mb\u001b[49m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m relu(out)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (100) must match the size of tensor b (10) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "batch = generator.generate_batch(100)\n",
    "fmodel(params, batch.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d55288c-aedf-4053-90cc-bc99010725c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46e5cb0c-9ef7-4459-8757-e4aeffface60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3695, 0.0000, 0.0000,  ..., 0.2397, 0.4215, 0.2793],\n",
       "        [0.1911, 0.0821, 0.0000,  ..., 0.3861, 0.9307, 0.4032],\n",
       "        [0.2011, 0.0000, 0.0000,  ..., 0.0810, 0.0374, 0.0000],\n",
       "        ...,\n",
       "        [0.2143, 0.1500, 0.0000,  ..., 0.0679, 0.1889, 0.0056],\n",
       "        [0.0772, 0.0897, 0.0000,  ..., 0.0863, 0.4066, 0.0000],\n",
       "        [0.1200, 0.0000, 0.0000,  ..., 0.0259, 0.0352, 0.0371]],\n",
       "       device='cuda:0', grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4484ef2-a119-4b3a-ab31-5358ddd094c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "\n",
    "def optimize(\n",
    "    model, \n",
    "    n_batch=1024,\n",
    "    steps=10_000,\n",
    "    print_freq=100,\n",
    "    lr=1e-3,\n",
    "    lr_scale=constant_lr,\n",
    "    hooks=[]\n",
    "):\n",
    "    cfg = model.config\n",
    "\n",
    "    opt = AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "    for i in tqdm(range(steps)):\n",
    "        for step in t:\n",
    "            step_lr = lr * lr_scale(step, steps)\n",
    "            for group in opt.param_groups:\n",
    "                group['lr'] = step_lr\n",
    "          opt.zero_grad(set_to_none=True)\n",
    "      batch = model.generate_batch(n_batch)\n",
    "      out = model(batch)\n",
    "      error = (model.importance*(batch.abs() - out)**2)\n",
    "      loss = einops.reduce(error, 'b i f -> i', 'mean').sum()\n",
    "      loss.backward()\n",
    "      opt.step()\n",
    "    \n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
